# -*- coding: utf-8 -*-
"""ThumbnailAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1__aN-m6wM43SQbnk9ihiBtiO5qAG1rk7
"""

# Install required packages and dependencies
!apt-get install tesseract-ocr -y
!pip install pytesseract textblob opencv-python-headless deepface
!python -m textblob.download_corpora

import requests
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image, ImageStat
from io import BytesIO
import pytesseract
from textblob import TextBlob
import cv2
import numpy as np
import math
import time
from deepface import DeepFace
from google.colab import files

# Load OpenCV's pre-trained Haar Cascade for face detection
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# -----------------------------
# Configuration
# -----------------------------
API_KEY = 'AIzaSyBBg9dOi0s1tZ5EUqkBJVrii198VL_B840'  # Your provided API key
channel_handle = 'lorealparisindia'  # Custom handle from the channel URL
TARGET_VIDEO_COUNT = 150           # Number of videos to retrieve

# -----------------------------
# Step 1: Retrieve Channel ID
# -----------------------------
search_channel_url = (
    f'https://www.googleapis.com/youtube/v3/search'
    f'?part=id&type=channel&q={channel_handle}&key={API_KEY}'
)
response = requests.get(search_channel_url)
data = response.json()
if not data.get('items'):
    raise ValueError(f"No channel found with handle '{channel_handle}'.")
channel_id = data['items'][0]['id'].get('channelId')
print("Channel ID:", channel_id)

# -----------------------------
# Step 2: Retrieve List of Videos (Up to 200)
# -----------------------------
video_info_list = []  # Each entry: {'video_id', 'title', 'thumbnail_url'}
video_ids = []        # For statistics lookup
nextPageToken = None

print(f"\nFetching up to {TARGET_VIDEO_COUNT} videos...")
while len(video_info_list) < TARGET_VIDEO_COUNT:
    video_search_url = (
        f'https://www.googleapis.com/youtube/v3/search'
        f'?key={API_KEY}&channelId={channel_id}&part=snippet'
        f'&order=date&type=video&maxResults=50'
    )
    if nextPageToken:
        video_search_url += f'&pageToken={nextPageToken}'

    response = requests.get(video_search_url)
    video_data = response.json()

    if not video_data.get('items'):
        print("No more videos found.")
        break

    for item in video_data.get('items', []):
        video_id = item['id']['videoId']
        title = item['snippet']['title']
        thumbnail_url = item['snippet']['thumbnails']['high']['url']
        video_ids.append(video_id)
        video_info_list.append({
            'video_id': video_id,
            'title': title,
            'thumbnail_url': thumbnail_url
        })
        if len(video_info_list) >= TARGET_VIDEO_COUNT:
            break

    nextPageToken = video_data.get('nextPageToken')
    if not nextPageToken:
        break  # No more pages
    time.sleep(0.1)  # brief sleep

print(f"Total videos fetched: {len(video_info_list)}")
if len(video_info_list) > TARGET_VIDEO_COUNT:
    video_info_list = video_info_list[:TARGET_VIDEO_COUNT]
    video_ids = video_ids[:TARGET_VIDEO_COUNT]

# -----------------------------
# Step 3: Retrieve Video Statistics
# -----------------------------
def chunks(lst, n):
    for i in range(0, len(lst), n):
        yield lst[i:i+n]

video_stats = {}
for chunk in chunks(video_ids, 50):
    ids_str = ','.join(chunk)
    video_details_url = (
        f'https://www.googleapis.com/youtube/v3/videos'
        f'?key={API_KEY}&id={ids_str}&part=snippet,statistics'
    )
    response = requests.get(video_details_url)
    details_data = response.json()
    for item in details_data.get('items', []):
        vid = item['id']
        stats = item.get('statistics', {})
        video_stats[vid] = {
            'viewCount': stats.get('viewCount', '0'),
            'likeCount': stats.get('likeCount', '0'),
            'commentCount': stats.get('commentCount', '0')
        }
    time.sleep(0.1)

# -----------------------------
# Step 4: Process Thumbnails: Download, Extended Image Analysis, OCR & Sentiment Analysis
# -----------------------------
results = []
print("\nProcessing video thumbnails and performing extended analysis...")

for video in video_info_list:
    vid = video['video_id']
    title = video['title']
    thumb_url = video['thumbnail_url']

    print("\n--------------------------------------------")
    print("Processing Video:", title)
    print("Video ID:", vid)
    print("Thumbnail URL:", thumb_url)

    try:
        # Download and open the thumbnail image
        img_response = requests.get(thumb_url)
        img_response.raise_for_status()
        img_data = img_response.content
        image = Image.open(BytesIO(img_data))

        # (Optional) Display the image
        plt.figure(figsize=(5, 5))
        plt.imshow(image)
        plt.axis('off')
        plt.title(title)
        plt.show()

        # Basic image properties from Pillow
        img_format = image.format
        width, height = image.size
        resolution = width * height
        aspect_ratio = width / height if height != 0 else None

        # Convert image to numpy array (RGB)
        image_array = np.array(image)

        # -----------------------------
        # Face Detection & Analysis using OpenCV and DeepFace
        # -----------------------------
        gray_cv = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)
        faces = face_cascade.detectMultiScale(gray_cv, scaleFactor=1.1, minNeighbors=5)
        num_faces = len(faces)
        face_present = num_faces > 0

        face_size_ratios = []
        dominant_emotions_list = []
        if num_faces > 0:
            for (x, y, w, h) in faces:
                face_area = w * h
                total_area = width * height
                face_size_ratios.append(face_area / total_area)
                # Crop face region (convert to BGR for DeepFace if needed)
                face_img = image_array[y:y+h, x:x+w]
                try:
                    analysis = DeepFace.analyze(face_img, actions=['emotion'], enforce_detection=False)
                    dominant_emotions_list.append(analysis.get('dominant_emotion', 'unknown'))
                except Exception as e:
                    dominant_emotions_list.append("error")
            face_size_ratios_str = ','.join([f"{ratio:.4f}" for ratio in face_size_ratios])
            dominant_emotions_str = ','.join(dominant_emotions_list)
        else:
            face_size_ratios_str = None
            dominant_emotions_str = None

        # -----------------------------
        # OCR and Sentiment Analysis on Extracted Text
        # -----------------------------
        ocr_text = pytesseract.image_to_string(image)
        ocr_text_clean = ocr_text.strip()
        if ocr_text_clean:
            blob = TextBlob(ocr_text_clean)
            sentiment = blob.sentiment
            polarity = sentiment.polarity
            subjectivity = sentiment.subjectivity
        else:
            polarity = None
            subjectivity = None

        # -----------------------------
        # Compute Additional Image Metrics
        # -----------------------------
        # Brightness and Contrast using ImageStat (grayscale)
        stat = ImageStat.Stat(image.convert('L'))
        brightness = stat.mean[0]
        contrast = stat.stddev[0]

        # Saturation & Hue: convert RGB image to HSV using OpenCV
        hsv = cv2.cvtColor(image_array, cv2.COLOR_RGB2HSV)
        saturation = float(np.mean(hsv[..., 1]))
        hue = float(np.mean(hsv[..., 0]))

        # Estimated Gamma (heuristic)
        normalized_brightness = brightness / 255.0
        estimated_gamma = math.log(normalized_brightness) / math.log(0.5) if normalized_brightness > 0 else None

        # Sharpness: Variance of Laplacian on grayscale image
        sharpness = float(cv2.Laplacian(gray_cv, cv2.CV_64F).var())

        # White Balance Deviation: difference between max and min channel means
        channel_means = np.mean(image_array, axis=(0,1))
        white_balance_deviation = float(max(channel_means) - min(channel_means))

        # Exposure: using brightness as a proxy
        exposure = brightness

        # -----------------------------
        # Retrieve Video Statistics
        # -----------------------------
        stats = video_stats.get(vid, {})
        views = stats.get('viewCount', '0')
        likes = stats.get('likeCount', '0')
        comments = stats.get('commentCount', '0')

        # -----------------------------
        # Append all collected data to results
        # -----------------------------
        results.append({
            'Video ID': vid,
            'Title': title,
            'Views': views,          # "Views" column for later view analysis
            'Likes': likes,
            'Comments': comments,
            'Thumbnail URL': thumb_url,
            'Extracted Text': ocr_text_clean,
            'Sentiment Polarity': polarity,
            'Sentiment Subjectivity': subjectivity,
            'Image Format': img_format,
            'Width': width,
            'Height': height,
            'Resolution': resolution,
            'Aspect Ratio': aspect_ratio,
            'Brightness': brightness,
            'Contrast': contrast,
            'Saturation': saturation,
            'Hue': hue,
            'Estimated Gamma': estimated_gamma,
            'Sharpness': sharpness,
            'White Balance Deviation': white_balance_deviation,
            'Exposure': exposure,
            'Face Present': face_present,
            'Num Faces': num_faces,
            'Face Size Ratios': face_size_ratios_str,
            'Dominant Emotions': dominant_emotions_str
        })

    except Exception as e:
        print("Error processing video thumbnail:", e)

# -----------------------------
# Step 5: Save the Collected Data and Export to CSV
# -----------------------------
df = pd.DataFrame(results)
print("\nFinal Results (DataFrame):")
display(df)

csv_filename = 'youtube_video_data_extended.csv'
df.to_csv(csv_filename, index=False)
print(f"\nData saved to {csv_filename}")

# Trigger file download (in Colab)
try:
    files.download(csv_filename)
except Exception as e:
    print("File download not supported in this environment.", e)